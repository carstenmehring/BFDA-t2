<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Felix Schönbrodt" />


<title>Bayes factor design analysis</title>

<script src="BFDA_manual_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="BFDA_manual_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="BFDA_manual_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="BFDA_manual_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="BFDA_manual_files/bootstrap-3.3.5/shim/respond.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="BFDA_manual_files/highlight/default.css"
      type="text/css" />
<script src="BFDA_manual_files/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<div class="container-fluid main-container">

<!-- tabsets -->
<script src="BFDA_manual_files/navigation-1.1/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Bayes factor design analysis</h1>
<h4 class="author"><em>Felix Schönbrodt</em></h4>
<h4 class="date"><em>4 August 2016</em></h4>

</div>


<p>This document demonstrates how to do a design analysis (aka. power analysis) for studies which use Bayes factors as index of evidence. For more details about Bayes Factor Design Analysis (BFDA), see our paper:</p>
<blockquote>
<p>Schönbrodt, F. D. and Wagenmakers, E.-J. (2016). Bayes Factor Design Analysis: Planning for Compelling Evidence. Available at SSRN: <a href="http://ssrn.com/abstract=2722435">http://ssrn.com/abstract=2722435</a></p>
</blockquote>
<div id="installation" class="section level2">
<h2>Installation</h2>
<p>The BFDA package is not on CRAN yet, but you can install the development version from Github:</p>
<pre class="r"><code>library(devtools)
install_github(&quot;nicebread/BFDA&quot;, subdir=&quot;package&quot;)</code></pre>
</div>
<div id="the-general-workflow" class="section level2">
<h2>The general workflow</h2>
<ol style="list-style-type: decimal">
<li>Simulate many hypothetical studies, both under H1 and under H0, using the function <code>BFDA.sim</code></li>
<li>Analyze the simulated studies, using the function <code>BFDA.analyze</code></li>
<li>Plot the simulated studies (<code>plot</code>, <code>SSD</code>, <code>compDist</code>)</li>
<li>Tune your design in a way that you achieve the desired goals with adequate probability (<code>SSD</code>)</li>
</ol>
<p>To summarize, the general workflow is (here shown without parameters; these are discussed later):</p>
<pre class="r"><code>sim.H1 &lt;- BFDA.sim(expected.ES = 0.5, ...)
sim.H0 &lt;- BFDA.sim(expected.ES = 0, ...)

BFDA.analyze(H1)
BFDA.analyze(H0)

plot(sim.H1)
plot(sim.H0)

SSD(sim.H1)
SSD(sim.H0)</code></pre>
</div>
<div id="simulating-hypothetical-studies-for-a-prospective-design-analysis" class="section level2">
<h2>1. Simulating hypothetical studies for a prospective design analysis</h2>
<p>As we do not know in advance whether H1 or H0 provide a better predictive performance of real world data, we want to evaluate the performance of a design under <em>both</em> hypotheses. Hence, we have to simulate a “H1 world” and a “H0 world”:</p>
<pre class="r"><code>sim.H1 &lt;- BFDA.sim(expected.ES=0.5, type=&quot;t.between&quot;, n.min=20, n.max=300, alternative=&quot;directional&quot;, boundary=Inf, B=1000, verbose=TRUE, cores=2)

sim.H0 &lt;- BFDA.sim(expected.ES=0, type=&quot;t.between&quot;, n.min=20, n.max=300, alternative=&quot;directional&quot;, boundary=Inf, B=1000, verbose=TRUE, cores=2)</code></pre>
<p>Let’s go through the most important parameters (for a full list of options, see <code>?BFDA.sim</code>):</p>
<ul>
<li><code>expected.ES</code>: The assumed effect size (ES). In classical power analysis, this is a fixed number. Here, you can also provide a vector, which quantifies the uncertainty about the true ES. For example: <code>expected.ES=rnorm(100000, 0.5, 0.1)</code>. If a vector is provided, a new ES is drawn from this vector for each simulated study. The <strong>metric</strong> for <code>expected.ES</code> depends on the type of design (see net bullet point):
<ul>
<li><code>type = &quot;t.between</code> or <code>type = &quot;t.paired</code>“: expected.ES has to be provided as Cohen’s <em>d</em></li>
<li><code>type = &quot;correlation&quot;</code>: expected.ES has to be provided as correlation</li>
</ul></li>
<li><code>type</code>: Type of design. Currently, 3 designs are implemented: A between-group t-test (“t.between”), a paired t-test (“t.paired”), and correlations (“correlation”)</li>
<li><code>n.min</code> and <code>n.max</code>: The initial sample size and the maximum sample size that is tested in the sequential procedure.</li>
<li><code>alternative</code>: Either “directional” for directed hypotheses (default) or “undirected” for two-sided tests</li>
<li><code>B</code>: Number of simulated studies. Aim for B &gt;= 10,000 for stable results (in this document we use B=1000 to save some computation time).</li>
<li><code>cores</code>: Multicore support. Add as many cores as you have to speed up computations.</li>
</ul>
<p>The simulations of the “H1 world” and a “H0 world” should have the same parameters (alternative, rscale, boundary, n.min) except the <code>expected.ES</code> (in the actual data analysis, we will apply the same test to the data set, regardless whether data came from H0 or H1 (what we don’t know anyway.)).</p>
<p>The BFDA uses the BayesFactor package to compute between and paired t-test. By default, it uses an rscale of sqrt(2)/2 for the JZS prior on effect sizes under H1. For correlations, it uses the code provided by Wagenmakers, E. J., Verhagen, J., &amp; Ly, A. (2016). How to quantify the evidence for the absence of a correlation. Behavior Research Methods, 1–14. <a href="http://doi.org/10.3758/s13428-015-0593-0">http://doi.org/10.3758/s13428-015-0593-0</a> (see <a href="https://osf.io/cabmf/">https://osf.io/cabmf/</a>).</p>
<p>By default, a full sequential design without evidential stopping threshold is simulated. That means, … That allows to extract …</p>
</div>
<div id="analyze-the-simulations" class="section level2">
<h2>2. Analyze the simulations</h2>
<p>Next, we can retrieve summary statistics from our simulations. For these summaries, we can define evidential thresholds (“How”), minimal and maximal sample sizes</p>
<p>For example, we can get the operational characteristics of a <strong>fixed-n design</strong>:</p>
<pre class="r"><code>BFDA.analyze(sim.H1, design=&quot;fixed&quot;, n.max=50, boundary=6)</code></pre>
<pre><code>## 52% showed evidence for H1 (BF &gt; 6)
## 46% were inconclusive (0.1667 &lt; BF &lt; 6)
## 2% showed evidence for H0 (BF &lt; 0.1667)</code></pre>
<pre class="r"><code>BFDA.analyze(sim.H0, design=&quot;fixed&quot;, n.max=50, boundary=6)</code></pre>
<pre><code>## 0% showed evidence for H1 (BF &gt; 6)
## 55% were inconclusive (0.1667 &lt; BF &lt; 6)
## 45% showed evidence for H0 (BF &lt; 0.1667)</code></pre>
<p>And for a <strong>sequential design</strong>:</p>
<pre class="r"><code>BFDA.analyze(sim.H1, design=&quot;sequential&quot;, n.min=20, n.max=300, boundary=10)</code></pre>
<pre><code>##                             outcome percentage
## 1      Studies terminating at n.max         0%
## 2 Studies terminating at a boundary       100%
## 3    --&gt; Terminating at H1 boundary        99%
## 4    --&gt; Terminating at H0 boundary         1%
## 
## Average sample number (ASN) at stopping point (both boundary hits and n.max): n = 59
## 
## Sample number quantiles (50/80/90/95%) at stopping point:
## 50% 80% 90% 95% 
##  46  89 110 131</code></pre>
<p>Here, all studies hit a boundary before n.max is reached. If we reduce n.max, some studies do not reach an evidential threshold:</p>
<pre class="r"><code>BFDA.analyze(sim.H1, design=&quot;sequential&quot;, n.min=20, n.max=100, boundary=10)</code></pre>
<pre><code>##                             outcome percentage
## 1      Studies terminating at n.max        15%
## 2 Studies terminating at a boundary        85%
## 3    --&gt; Terminating at H1 boundary        84%
## 4    --&gt; Terminating at H0 boundary         1%
## 
## Of 15% of studies terminating at n.max:
## 10% showed evidence for H1 (BF &gt; 3)
## 5% were inconclusive (3 &gt; BF &gt; 1/3)
## 0% showed evidence for H0 (BF &lt; 1/3)
## 
## Average sample number (ASN) at stopping point (both boundary hits and n.max): n = 54
## 
## Sample number quantiles (50/80/90/95%) at stopping point:
## 50% 80% 90% 95% 
##  46  89 100 100</code></pre>
</div>
<div id="plots-the-design-analysis" class="section level2">
<h2>3. Plots the design analysis</h2>
<div id="compare-distributions-of-bfs-for-a-fixed-n" class="section level3">
<h3>Compare distributions of BFs for a fixed <em>n</em></h3>
<pre class="r"><code>compDist(BFDA.H1=sim.H1, BFDA.H0=sim.H0, n=50, boundary=c(1/6, 6), xlim=c(1/11, 31))</code></pre>
<p><img src="BFDA_manual_files/figure-html/compDist-1.png" width="672" /></p>
</div>
<div id="open-ended-sequential-design" class="section level3">
<h3>Open-ended sequential design</h3>
<p>Under H1:</p>
<pre class="r"><code>plot(sim.H1, n.min=20, boundary=c(1/6, 6))</code></pre>
<p><img src="BFDA_manual_files/figure-html/SBF1-1.png" width="672" /></p>
<p>Under H0:</p>
<pre class="r"><code>plot(sim.H0, n.min=20, boundary=c(1/6, 6))</code></pre>
<p><img src="BFDA_manual_files/figure-html/SBF0-1.png" width="672" /></p>
</div>
<div id="sequential-design-with-n.max-and-asymmetric-boundaries" class="section level3">
<h3>Sequential design with n.max and asymmetric boundaries</h3>
<p>Under H1:</p>
<pre class="r"><code>plot(sim.H1, n.min=20, n.max=80, boundary=c(1/5, 10))</code></pre>
<p><img src="BFDA_manual_files/figure-html/SBF_nmax-1.png" width="672" /></p>
</div>
</div>
<div id="sample-size-determination-ssd" class="section level2">
<h2>4. Sample Size Determination (SSD)</h2>
<p>What sample size do you need to ensure, say, 80% probability that a study design finds an effect of size, say, 0.5 with a BF &gt;= 10?</p>
<pre class="r"><code>SSD(sim.H1, power=.80, boundary=c(1/10, 10))</code></pre>
<pre><code>## A &gt;= 80% (actual: 80%) power achieved at n = 110
## This setting implies long-term rates of:
## 20% inconclusive results and
##    0% false-negative results.</code></pre>
<p><img src="BFDA_manual_files/figure-html/SSD1-1.png" width="672" /></p>
<p>What sample size do I need to have less than 1% of studies with a false positive error, if I set the boundary to 3? (Note: A BF threshold of 3 is in almost all applications too lenient! Aim for a BF of at least 5).</p>
<pre class="r"><code>SSD(sim.H0, alpha=.01, boundary=c(1/3, 3))</code></pre>
<pre><code>## A &lt;= 1% (actual: 1%) long-term rate of Type-I errors is achieved at n = 25
## This setting implies long-term rates of:
##    24% inconclusive results and
##    75% true-negative results.</code></pre>
<p><img src="BFDA_manual_files/figure-html/SSD2-1.png" width="672" /></p>
<p>Note: The SSD function automatically detects whether a H1 or a H0 simulation is analyzed.</p>
</div>
<div id="use-case-apply-for-a-grant-with-sequential-sampling" class="section level1">
<h1>Use case: Apply for a grant with sequential sampling</h1>
<p>Granting agencies probably want a fixed sample size in the planning stage in order to quantify the amount of funding. For how much participant renumeration should one apply when using a sequential design?</p>
<p>We suggest to determine the requested sample size using two different design analyses:</p>
<ol style="list-style-type: decimal">
<li>Compute an open-ended SBF design with the expected sample size to get a distribution of sample sizes at stopping point.</li>
<li>Compute the 80% quantile of stopping-ns: n_q80</li>
<li>Evaluate the characteristics of a <em>SBF+maxN</em> design with n.max = n_q80. Does it have acceptable false positive and false negative error rates? What is the mean and median expected sample size?</li>
</ol>
<pre class="r"><code># We use the simulation from above. 
# Check the expected sample sizes for an evidential boundary of 10
a1 &lt;- BFDA.analyze(sim.H1, design=&quot;sequential&quot;, n.min=20, n.max=NA, boundary=10)

# --&gt; see 80% quantile in output
a1</code></pre>
<pre><code>##                             outcome percentage
## 1      Studies terminating at n.max       0.1%
## 2 Studies terminating at a boundary      99.9%
## 3    --&gt; Terminating at H1 boundary      99.9%
## 4    --&gt; Terminating at H0 boundary         0%
## 
## Of 0.1% of studies terminating at n.max:
## 0.1% showed evidence for H1 (BF &gt; 3)
## 0% were inconclusive (3 &gt; BF &gt; 1/3)
## 0% showed evidence for H0 (BF &lt; 1/3)
## 
## Average sample number (ASN) at stopping point (both boundary hits and n.max): n = 58
## 
## Sample number quantiles (50/80/90/95%) at stopping point:
## 50% 80% 90% 95% 
##  45  86 115 140</code></pre>
<pre class="r"><code># Alternative approach: access stopping-ns directly
n_q80 &lt;- ceiling(quantile(a1$endpoint.n, prob=.80))
n_q80</code></pre>
<pre><code>## 80% 
##  86</code></pre>
<p>80% of all studies stop earlier than n = 86. How does a design with that n.max perform concerning rates of misleading evidence?</p>
<pre class="r"><code>BFDA.analyze(sim.H1, design=&quot;sequential&quot;, n.min=20, n.max=n_q80, boundary=10)</code></pre>
<pre><code>##                             outcome percentage
## 1      Studies terminating at n.max      19.7%
## 2 Studies terminating at a boundary      80.3%
## 3    --&gt; Terminating at H1 boundary      80.3%
## 4    --&gt; Terminating at H0 boundary         0%
## 
## Of 19.7% of studies terminating at n.max:
## 7.3% showed evidence for H1 (BF &gt; 3)
## 12.1% were inconclusive (3 &gt; BF &gt; 1/3)
## 0.3% showed evidence for H0 (BF &lt; 1/3)
## 
## Average sample number (ASN) at stopping point (both boundary hits and n.max): n = 51
## 
## Sample number quantiles (50/80/90/95%) at stopping point:
## 50% 80% 90% 95% 
##  45  86  86  86</code></pre>
<pre class="r"><code>BFDA.analyze(sim.H0, design=&quot;sequential&quot;, n.min=20, n.max=n_q80, boundary=10)</code></pre>
<pre><code>##                             outcome percentage
## 1      Studies terminating at n.max      62.2%
## 2 Studies terminating at a boundary      37.8%
## 3    --&gt; Terminating at H1 boundary       2.2%
## 4    --&gt; Terminating at H0 boundary      35.6%
## 
## Of 62.2% of studies terminating at n.max:
## 0.6% showed evidence for H1 (BF &gt; 3)
## 18.8% were inconclusive (3 &gt; BF &gt; 1/3)
## 42.8% showed evidence for H0 (BF &lt; 1/3)
## 
## Average sample number (ASN) at stopping point (both boundary hits and n.max): n = 74
## 
## Sample number quantiles (50/80/90/95%) at stopping point:
## 50% 80% 90% 95% 
##  86  86  86  86</code></pre>
<p>In this design analysis for the <em>SBF+maxN</em> design, we can see that, although we apply for 86 participants in each group, we can expect to stop with 45 participants or less with a 50% chance, if H1 is true. The false negative rate is virtually 0%. That means, if the effect exists in the expected size, this design virtually guarantees to detect it.</p>
<p>Under H0, at least half of the studies will have to use the full requested sample of 86 participants. We have a 2.2% false positive error rate, and 35.6% of all studies will correctly stop at the H0 boundary. The remaining 62.2% of all studies will remain inconclusive with respect to the desired evidential threshold of <span class="math">\(BF_{10}\)</span> &lt;= 1/10. However, the Bayes factor of these studies can still be interpreted in size and direction.</p>
<p>In the grant application, you can write that the study has a 80% chance to provide compelling evidence either for or against the focal hypothesis. You could also mention that studies failing to reach the threshold for compelling evidence are not necessarily a “failure”, but that their BF can still be interpreted, and in XX% of all cases will point into the correct direction.</p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
